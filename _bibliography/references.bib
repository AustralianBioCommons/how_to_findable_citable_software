
@techreport{del_pico_fairsoft_2022,
	type = {preprint},
	title = {{FAIRsoft} - {A} practical implementation of {FAIR} principles for research software},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.05.04.490563},
	abstract = {Abstract 
          Software plays a crucial and growing role in research. Unfortunately, the computational component in Life Sciences research is challenging to reproduce and verify most of the time. It could be undocumented, opaque, may even contain unknown errors that affect the outcome, or be directly unavailable, and impossible to use by others. These issues are detrimental to the overall quality of scientific research. One step to address this problem is the formulation of principles that research software in the domain should meet to ensure its quality and sustainability, resembling the FAIR (Findable, Accessible, Interoperable and Reusable) Data Principles. Within the ELIXIR infrastructure, OpenEBench aims to be an open platform providing both support for scientific benchmarking and an active observatory of software quality for the universe of Life Sciences research software. We present our initial proposal to instantiate a FAIR-like framework for assessing software quality as the first step toward the implementation of such an observatory in OpenEBench. 
           
            Supplementary Material: 
            FAIRsoft - Supplementary materials FAIRsoft.SupplementaryTables FAIRsoft.SupplementaryTables-Landscape 
           
           
            Other Figures: 
            figures draft 
           
           
            Repository: 
            https://gitlab.bsc.es/inb/elixir/software-observatory/FAIRsoft\_ETL},
	language = {en},
	urldate = {2024-02-12},
	institution = {Bioinformatics},
	author = {Del Pico, Eva Martín and Gelpi, Josep Lluis and Capella-Gutiérrez, Salvador},
	month = may,
	year = {2022},
	doi = {10.1101/2022.05.04.490563},
}

@misc{noauthor_biojs_nodate,
	title = {{BioJS}},
	url = {https://biojs.net/#/},
	urldate = {2023-11-14},
}

@misc{noauthor_fdi_nodate,
	title = {{FDI} {Lab} - {SciCrunch}.org {\textbar} {Welcome}...},
	url = {https://scicrunch.org/},
	abstract = {Base community for the SciCrunch.org infrastructure},
	urldate = {2023-11-14},
}

@article{da_veiga_leprevost_biocontainers_2017,
	title = {{BioContainers}: an open-source and community-driven framework for software standardization},
	volume = {33},
	issn = {1367-4803, 1367-4811},
	shorttitle = {{BioContainers}},
	url = {https://academic.oup.com/bioinformatics/article/33/16/2580/3096437},
	doi = {10.1093/bioinformatics/btx192},
	abstract = {Abstract 
             
              Motivation 
              BioContainers (biocontainers.pro) is an open-source and community-driven framework which provides platform independent executable environments for bioinformatics software. BioContainers allows labs of all sizes to easily install bioinformatics software, maintain multiple versions of the same software and combine tools into powerful analysis pipelines. BioContainers is based on popular open-source projects Docker and rkt frameworks, that allow software to be installed and executed under an isolated and controlled environment. Also, it provides infrastructure and basic guidelines to create, manage and distribute bioinformatics containers with a special focus on omics technologies. These containers can be integrated into more comprehensive bioinformatics pipelines and different architectures (local desktop, cloud environments or HPC clusters). 
             
             
              Availability and Implementation 
              The software is freely available at github.com/BioContainers/.},
	language = {en},
	number = {16},
	urldate = {2023-11-14},
	journal = {Bioinformatics},
	author = {Da Veiga Leprevost, Felipe and Grüning, Björn A and Alves Aflitos, Saulo and Röst, Hannes L and Uszkoreit, Julian and Barsnes, Harald and Vaudel, Marc and Moreno, Pablo and Gatto, Laurent and Weber, Jonas and Bai, Mingze and Jimenez, Rafael C and Sachsenberg, Timo and Pfeuffer, Julianus and Vera Alvarez, Roberto and Griss, Johannes and Nesvizhskii, Alexey I and Perez-Riverol, Yasset},
	editor = {Valencia, Alfonso},
	month = aug,
	year = {2017},
	pages = {2580--2582},
}

@article{li_sequence_2009,
	title = {The {Sequence} {Alignment}/{Map} format and {SAMtools}},
	volume = {25},
	issn = {1367-4811, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article/25/16/2078/204688},
	doi = {10.1093/bioinformatics/btp352},
	abstract = {Abstract 
            Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. 
            Availability:  http://samtools.sourceforge.net 
            Contact:  rd@sanger.ac.uk},
	language = {en},
	number = {16},
	urldate = {2023-11-09},
	journal = {Bioinformatics},
	author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard and {1000 Genome Project Data Processing Subgroup}},
	month = aug,
	year = {2009},
	pages = {2078--2079},
}

@article{quinlan_bedtools_2010,
	title = {{BEDTools}: a flexible suite of utilities for comparing genomic features},
	volume = {26},
	issn = {1367-4811, 1367-4803},
	shorttitle = {{BEDTools}},
	url = {https://academic.oup.com/bioinformatics/article/26/6/841/244688},
	doi = {10.1093/bioinformatics/btq033},
	abstract = {Abstract 
            Motivation: Testing for correlations between different sets of genomic features is a fundamental task in genomics research. However, searching for overlaps between features with existing web-based methods is complicated by the massive datasets that are routinely produced with current sequencing technologies. Fast and flexible tools are therefore required to ask complex questions of these data in an efficient manner. 
            Results: This article introduces a new software suite for the comparison, manipulation and annotation of genomic features in Browser Extensible Data (BED) and General Feature Format (GFF) format. BEDTools also supports the comparison of sequence alignments in BAM format to both BED and GFF features. The tools are extremely efficient and allow the user to compare large datasets (e.g. next-generation sequencing data) with both public and custom genome annotation tracks. BEDTools can be combined with one another as well as with standard UNIX commands, thus facilitating routine genomics tasks as well as pipelines that can quickly answer intricate questions of large genomic datasets. 
            Availability and implementation: BEDTools was written in C++. Source code and a comprehensive user manual are freely available at http://code.google.com/p/bedtools 
            Contact:  aaronquinlan@gmail.com; imh4y@virginia.edu 
            Supplementary information:  Supplementary data are available at Bioinformatics online.},
	language = {en},
	number = {6},
	urldate = {2023-11-09},
	journal = {Bioinformatics},
	author = {Quinlan, Aaron R. and Hall, Ira M.},
	month = mar,
	year = {2010},
	pages = {841--842},
}

@article{chue_hong_software_2019,
	title = {Software {Citation} {Checklist} for {Developers}},
	copyright = {Creative Commons Attribution Share Alike 4.0 International, Open Access},
	url = {https://zenodo.org/record/3482768},
	doi = {10.5281/ZENODO.3482768},
	abstract = {This document provides a minimal, generic checklist that developers of software (either open or closed source) used in research can use to ensure they are following good practice around software citation. This will help developers get credit for the software they create, and improve transparency, reproducibility, and reuse.},
	language = {en},
	urldate = {2023-11-09},
	author = {Chue Hong, Neil P. and Allen, Alice and {Gonzalez-Beltran} and de Waard, Anita and Smith, Arfon M. and Robinson, Carly and Jones, Catherine and Bouquin, Daina and Katz, Daniel S. and Kennedy, David and Ryder, Gerry and Hausman, Jessica and Hwang, Lorraine and Jones, Matthew B. and Harrison, Melissa and Crosas, Mercè and Wu, Mingfang and Löwe, Peter and Haines, Robert and Edmunds, Scott and Stall, Shelley and Swaminathan, Sowmya and Druskat, Stephan and Crick, Tom and Morrell, Tom and Pollard, Tom},
	month = oct,
	year = {2019},
	keywords = {software citation},
}

@misc{chue_hong_which_nodate,
	title = {In which journals should {I} publish my software?},
	url = {https://www.software.ac.uk/top-tip/which-journals-should-i-publish-my-software},
	author = {Chue Hong, Neil},
}

@article{romano_ten_2020,
	title = {Ten simple rules for writing a paper about scientific software},
	volume = {16},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1008390},
	doi = {10.1371/journal.pcbi.1008390},
	abstract = {Papers describing software are an important part of computational fields of scientific research. These “software papers” are unique in a number of ways, and they require special consideration to improve their impact on the scientific community and their efficacy at conveying important information. Here, we discuss 10 specific rules for writing software papers, covering some of the different scenarios and publication types that might be encountered, and important questions from which all computational researchers would benefit by asking along the way.},
	language = {en},
	number = {11},
	urldate = {2023-11-09},
	journal = {PLOS Computational Biology},
	author = {Romano, Joseph D. and Moore, Jason H.},
	editor = {Markel, Scott},
	month = nov,
	year = {2020},
	pages = {e1008390},
}

@misc{noauthor_datacite_nodate,
	title = {{DataCite} {Commons}},
	url = {https://commons.datacite.org/statistics},
	urldate = {2023-11-09},
}

@misc{fenner_doi_2018,
	title = {{DOI} {Registrations} for {Software}},
	url = {https://datacite.org/blog/doi-registrations-software/},
	abstract = {We know that software is important in research, and some of us in the scholarly communications community, for example, in FORCE11, have been pushing the concept of software citation as […]},
	language = {en\_US},
	urldate = {2023-11-09},
	journal = {DataCite},
	author = {Fenner, Martin},
	month = may,
	year = {2018},
}

@article{huber_orchestrating_2015,
	title = {Orchestrating high-throughput genomic analysis with {Bioconductor}},
	volume = {12},
	issn = {1548-7091, 1548-7105},
	url = {https://www.nature.com/articles/nmeth.3252},
	doi = {10.1038/nmeth.3252},
	language = {en},
	number = {2},
	urldate = {2023-11-09},
	journal = {Nature Methods},
	author = {Huber, Wolfgang and Carey, Vincent J and Gentleman, Robert and Anders, Simon and Carlson, Marc and Carvalho, Benilton S and Bravo, Hector Corrada and Davis, Sean and Gatto, Laurent and Girke, Thomas and Gottardo, Raphael and Hahne, Florian and Hansen, Kasper D and Irizarry, Rafael A and Lawrence, Michael and Love, Michael I and MacDonald, James and Obenchain, Valerie and Oleś, Andrzej K and Pagès, Hervé and Reyes, Alejandro and Shannon, Paul and Smyth, Gordon K and Tenenbaum, Dan and Waldron, Levi and Morgan, Martin},
	month = feb,
	year = {2015},
	pages = {115--121},
}

@article{molder_sustainable_2021,
	title = {Sustainable data analysis with {Snakemake}},
	volume = {10},
	issn = {2046-1402},
	url = {https://f1000research.com/articles/10-33/v1},
	doi = {10.12688/f1000research.29032.1},
	abstract = {Data analysis often entails a multitude of heterogeneous steps, from the application of various command line tools to the usage of scripting languages like R or Python for the generation of plots and tables. It is widely recognized that data analyses should ideally be conducted in a reproducible way. Reproducibility enables technical validation and regeneration of results on the original or even new data. However, reproducibility alone is by no means sufficient to deliver an analysis that is of lasting impact (i.e., sustainable) for the field, or even just one research group. We postulate that it is equally important to ensure adaptability and transparency. The former describes the ability to modify the analysis to answer extended or slightly different research questions. The latter describes the ability to understand the analysis in order to judge whether it is not only technically, but methodologically valid. 
            Here, we analyze the properties needed for a data analysis to become reproducible, adaptable, and transparent. We show how the popular workflow management system Snakemake can be used to guarantee this, and how it enables an ergonomic, combined, unified representation of all steps involved in data analysis, ranging from raw data processing, to quality control and fine-grained, interactive exploration and plotting of final results.},
	language = {en},
	urldate = {2023-11-09},
	journal = {F1000Research},
	author = {Mölder, Felix and Jablonski, Kim Philipp and Letcher, Brice and Hall, Michael B. and Tomkins-Tinch, Christopher H. and Sochat, Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O. and Kanitz, Alexander and Wilm, Andreas and Holtgrewe, Manuel and Rahmann, Sven and Nahnsen, Sven and Köster, Johannes},
	month = jan,
	year = {2021},
	pages = {33},
}

@article{ewels_nf-core_2020,
	title = {The nf-core framework for community-curated bioinformatics pipelines},
	volume = {38},
	issn = {1087-0156, 1546-1696},
	url = {https://www.nature.com/articles/s41587-020-0439-x},
	doi = {10.1038/s41587-020-0439-x},
	language = {en},
	number = {3},
	urldate = {2023-11-09},
	journal = {Nature Biotechnology},
	author = {Ewels, Philip A. and Peltzer, Alexander and Fillinger, Sven and Patel, Harshil and Alneberg, Johannes and Wilm, Andreas and Garcia, Maxime Ulysse and Di Tommaso, Paolo and Nahnsen, Sven},
	month = mar,
	year = {2020},
	pages = {276--278},
}

@article{sheynkman_using_2014,
	title = {Using {Galaxy}-{P} to leverage {RNA}-{Seq} for the discovery of novel protein variations},
	volume = {15},
	issn = {1471-2164},
	url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-703},
	doi = {10.1186/1471-2164-15-703},
	language = {en},
	number = {1},
	urldate = {2023-11-09},
	journal = {BMC Genomics},
	author = {Sheynkman, Gloria M and Johnson, James E and Jagtap, Pratik D and Shortreed, Michael R and Onsongo, Getiria and Frey, Brian L and Griffin, Timothy J and Smith, Lloyd M},
	month = dec,
	year = {2014},
	pages = {703},
}

@article{european_organization_for_nuclear_research_zenodo_2013,
	title = {Zenodo: {Research}. {Shared}.},
	shorttitle = {Zenodo},
	url = {https://www.zenodo.org/},
	doi = {10.25495/7GXK-RD71},
	abstract = {Zenodo is a general purpose repository that enables researchers, scientists, projects and institutions to share, preserve and showcase multidisciplinary research results (data, software and publications) that are not part of the existing institutional or subject-based repositories of the research communities. It is founded in the trustworthy CERN data centre.},
	language = {en},
	urldate = {2023-10-30},
	author = {{European Organization For Nuclear Research} and {OpenAIRE}},
	year = {2013},
	keywords = {Dataset, FOS: Physical sciences, Publication},
}

@article{gfz_german_research_centre_for_geosciences_registry_2013,
	title = {Registry of {Research} {Data} {Repositories}},
	url = {https://www.re3data.org/},
	doi = {10.17616/R3D},
	urldate = {2023-10-30},
	author = {{GFZ German Research Centre For Geosciences} and {Humboldt-Universität Zu Berlin} and {Germany  Karlsruhe Institute Of Technology (KIT)} and {Purdue University Libraries} and Bertelmann, Roland and Buys, Matt and Cousijn, Helena and Dierolf, Uwe and Elger, Kirsten and Fenner, Martin and Ferguson, Lea Maria and Fritze, Florian and Fuchs, Claudio and Goebelbecker, Hans-Jürgen and Gundlach, Jens and Kindling, Maxi and Kloska, Gabriele and Klump, Jens and Kramer, Claudia and Manova, Stefka and Pampel, Heinz and Petras, Vivien and Reuter, Evelyn and Rücknagel, Jessika and van de Sandt, Stephanie},
	year = {2013},
}

@article{yuen_dockstore_2021,
	title = {The {Dockstore}: enhancing a community platform for sharing reproducible and accessible computational protocols},
	volume = {49},
	issn = {0305-1048, 1362-4962},
	shorttitle = {The {Dockstore}},
	url = {https://academic.oup.com/nar/article/49/W1/W624/6274534},
	doi = {10.1093/nar/gkab346},
	abstract = {Abstract 
            Dockstore (https://dockstore.org/) is an open source platform for publishing, sharing, and finding bioinformatics tools and workflows. The platform has facilitated large-scale biomedical research collaborations by using cloud technologies to increase the Findability, Accessibility, Interoperability and Reusability (FAIR) of computational resources, thereby promoting the reproducibility of complex bioinformatics analyses. Dockstore supports a variety of source repositories, analysis frameworks, and language technologies to provide a seamless publishing platform for authors to create a centralized catalogue of scientific software. The ready-to-use packaging of hundreds of tools and workflows, combined with the implementation of interoperability standards, enables users to launch analyses across multiple environments. Dockstore is widely used, more than twenty-five high-profile organizations share analysis collections through the platform in a variety of workflow languages, including the Broad Institute's GATK best practice and COVID-19 workflows (WDL), nf-core workflows (Nextflow), the Intergalactic Workflow Commission tools (Galaxy), and workflows from Seven Bridges (CWL) to highlight just a few. Here we describe the improvements made over the last four years, including the expansion of system integrations supporting authors, the addition of collaboration features and analysis platform integrations supporting users, and other enhancements that improve the overall scientific reproducibility of Dockstore content.},
	language = {en},
	number = {W1},
	urldate = {2023-10-30},
	journal = {Nucleic Acids Research},
	author = {Yuen, Denis and Cabansay, Louise and Duncan, Andrew and Luu, Gary and Hogue, Gregory and Overbeck, Charles and Perez, Natalie and Shands, Walt and Steinberg, David and Reid, Chaz and Olunwa, Nneka and Hansen, Richard and Sheets, Elizabeth and O’Farrell, Ash and Cullion, Kim and O’Connor, Brian D and Paten, Benedict and Stein, Lincoln},
	month = jul,
	year = {2021},
	pages = {W624--W632},
}

@techreport{alves_elixir_2021,
	type = {preprint},
	title = {{ELIXIR} {Software} {Management} {Plan} for {Life} {Sciences}},
	url = {https://osf.io/k8znb},
	abstract = {Data Management Plans are now considered a key element of Open Science. They describe the data management life cycle for the data to be collected, processed and/or generated within the lifetime of a particular project or activity. A Software Manag ement Plan (SMP) plays the same role but for software. Beyond its management perspective, the main advantage of an SMP is that it both provides clear context to the software that is being developed and raises awareness. Although there are a few SMPs already available, most of them require significant technical knowledge to be effectively used. ELIXIR has developed a low-barrier SMP, specifically tailored for life science researchers, aligned to the FAIR Research Software principles. Starting from the Four Recommendations for Open Source Software, the ELIXIR SMP was iteratively refined by surveying the practices of the community and incorporating the received feedback. Currently available as a survey, future plans of the ELIXIR SMP include a human- and machine-readable version, that can be automatically queried and connected to relevant tools and metrics within the ELIXIR Tools ecosystem and beyond.},
	urldate = {2023-10-30},
	institution = {BioHackrXiv},
	author = {Alves, Renato and Bampalikis, Dimitrios and Castro, Leyla Jael and Fernández, José María and Harrow, Jennifer and Kuzak, Mateusz and Martin, Eva and Psomopoulos, Fotis E. and Via, Allegra},
	month = oct,
	year = {2021},
	doi = {10.37044/osf.io/k8znb},
}

@article{barker_introducing_2022,
	title = {Introducing the {FAIR} {Principles} for research software},
	volume = {9},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01710-x},
	doi = {10.1038/s41597-022-01710-x},
	abstract = {Abstract 
            Research software is a fundamental and vital part of research, yet significant challenges to discoverability, productivity, quality, reproducibility, and sustainability exist. Improving the practice of scholarship is a common goal of the open science, open source, and FAIR (Findable, Accessible, Interoperable and Reusable) communities and research software is now being understood as a type of digital object to which FAIR should be applied. This emergence reflects a maturation of the research community to better understand the crucial role of FAIR research software in maximising research value. The FAIR for Research Software (FAIR4RS) Working Group has adapted the FAIR Guiding Principles to create the FAIR Principles for Research Software (FAIR4RS Principles). The contents and context of the FAIR4RS Principles are summarised here to provide the basis for discussion of their adoption. Examples of implementation by organisations are provided to share information on how to maximise the value of research outputs, and to encourage others to amplify the importance and impact of this work.},
	language = {en},
	number = {1},
	urldate = {2023-10-30},
	journal = {Scientific Data},
	author = {Barker, Michelle and Chue Hong, Neil P. and Katz, Daniel S. and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom},
	month = oct,
	year = {2022},
	pages = {622},
}

@article{lott_futureproofing_2022,
	title = {Future‐proofing the koala: {Synergising} genomic and environmental data for effective species management},
	volume = {31},
	issn = {0962-1083, 1365-294X},
	shorttitle = {Future‐proofing the koala},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/mec.16446},
	doi = {10.1111/mec.16446},
	abstract = {Abstract 
             
              Climatic and evolutionary processes are inextricably linked to conservation. Avoiding extinction in rapidly changing environments often depends upon a species’ capacity to adapt in the face of extreme selective pressures. Here, we employed exon capture and high‐throughput next‐generation sequencing to investigate the mechanisms underlying population structure and adaptive genetic variation in the koala ( 
              Phascolarctos cinereus 
              ), an iconic Australian marsupial that represents a unique conservation challenge because it is not uniformly threatened across its range. An examination of 250 specimens representing 91 wild source locations revealed that five major genetic clusters currently exist on a continental scale. The initial divergence of these clusters appears to have been concordant with the Mid‐Brunhes Transition ({\textasciitilde}430 to 300 kya), a major climatic reorganisation that increased the amplitude of Pleistocene glacial‐interglacial cycles. While signatures of polygenic selection and environmental adaptation were detected, strong evidence for repeated, climate‐associated range contractions and demographic bottleneck events suggests that geographically isolated refugia may have played a more significant role in the survival of the koala through the Pleistocene glaciation than in situ adaptation. Consequently, the conservation of genome‐wide genetic variation must be aligned with the protection of core koala habitat to increase the resilience of vulnerable populations to accelerating anthropogenic threats. Finally, we propose that the five major genetic clusters identified in this study should be accounted for in future koala conservation efforts (e.g., guiding translocations), as existing management divisions in the states of Queensland and New South Wales do not reflect historic or contemporary population structure.},
	language = {en},
	number = {11},
	urldate = {2023-10-30},
	journal = {Molecular Ecology},
	author = {Lott, Matthew J. and Wright, Belinda R. and Neaves, Linda E. and Frankham, Greta J. and Dennison, Siobhan and Eldridge, Mark D. B. and Potter, Sally and Alquezar‐Planas, David E. and Hogg, Carolyn J. and Belov, Katherine and Johnson, Rebecca N.},
	editor = {Waits, Lisette},
	month = jun,
	year = {2022},
	pages = {3035--3055},
}

@article{atasoy_microbial_2023,
	title = {Microbial dynamics and bioreactor performance are interlinked with organic matter removal from wastewater treatment plant effluent},
	volume = {372},
	issn = {09608524},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960852423000858},
	doi = {10.1016/j.biortech.2023.128659},
	language = {en},
	urldate = {2023-10-30},
	journal = {Bioresource Technology},
	author = {Atasoy, M. and Scott Jr., W.T. and Van Gijn, K. and Koehorst, J.J. and Smidt, H. and Langenhoff, A.A.M.},
	month = mar,
	year = {2023},
	pages = {128659},
}

@article{satgunaseelan_viral_2022,
	title = {Viral {Integration} {Plays} a {Minor} {Role} in the {Development} and {Prognostication} of {Oral} {Squamous} {Cell} {Carcinoma}},
	volume = {14},
	issn = {2072-6694},
	url = {https://www.mdpi.com/2072-6694/14/21/5213},
	doi = {10.3390/cancers14215213},
	abstract = {Viruses are well known drivers of several human malignancies. A causative factor for oral cavity squamous cell carcinoma (OSCC) in patients with limited exposure to traditional risk factors, including tobacco use, is yet to be identified. Our study aimed to comprehensively evaluate the role of viral drivers in OSCC patients with low cumulative exposure to traditional risk factors. Patients under 50 years of age with OSCC, defined using strict anatomic criteria were selected for WGS. The WGS data was interrogated using viral detection tools (Kraken 2 and BLASTN), together examining {\textgreater}700,000 viruses. The findings were further verified using tissue microarrays of OSCC samples using both immunohistochemistry and RNA in situ hybridisation (ISH). 28 patients underwent WGS and comprehensive viral profiling. One 49-year-old male patient with OSCC of the hard palate demonstrated HPV35 integration. 657 cases of OSCC were then evaluated for the presence of HPV integration through immunohistochemistry for p16 and HPV RNA ISH. HPV integration was seen in 8 (1.2\%) patients, all middle-aged men with predominant floor of mouth involvement. In summary, a wide-ranging interrogation of {\textgreater}700,000 viruses using OSCC WGS data showed HPV integration in a minority of male OSCC patients and did not carry any prognostic significance.},
	language = {en},
	number = {21},
	urldate = {2023-10-30},
	journal = {Cancers},
	author = {Satgunaseelan, Laveniya and Strbenac, Dario and Tadi, Sahithi and Nguyen, Kevin and Wykes, James and Palme, Carsten E. and Low, Tsu-Hui (Hubert) and Yang, Jean Y. H. and Clark, Jonathan R. and Gupta, Ruta},
	month = oct,
	year = {2022},
	pages = {5213},
}

@article{guha_schemaorg_2015,
	title = {Schema.org: {Evolution} of {Structured} {Data} on the {Web}: {Big} data makes common schemas even more necessary.},
	volume = {13},
	issn = {1542-7730, 1542-7749},
	shorttitle = {Schema.org},
	url = {https://dl.acm.org/doi/10.1145/2857274.2857276},
	doi = {10.1145/2857274.2857276},
	abstract = {Separation between content and presentation has always been one of the important design aspects of the Web. Historically, however, even though most Web sites were driven off structured databases, they published their content purely in HTML. Services such as Web search, price comparison, reservation engines, etc. that operated on this content had access only to HTML. Applications requiring access to the structured data underlying these Web pages had to build custom extractors to convert plain HTML into structured data. These efforts were often laborious and the scrapers were fragile and error-prone, breaking every time a site changed its layout.},
	language = {en},
	number = {9},
	urldate = {2023-10-27},
	journal = {Queue},
	author = {Guha, R. V. and Brickley, Dan and MacBeth, Steve},
	month = nov,
	year = {2015},
	pages = {10--37},
}

@article{wood_improved_2019,
	title = {Improved metagenomic analysis with {Kraken} 2},
	volume = {20},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1891-0},
	doi = {10.1186/s13059-019-1891-0},
	abstract = {Abstract 
             
              Although Kraken’s 
              k 
              -mer-based approach provides a fast taxonomic classification of metagenomic sequence data, its large memory requirements can be limiting for some applications. Kraken 2 improves upon Kraken 1 by reducing memory usage by 85\%, allowing greater amounts of reference genomic data to be used, while maintaining high accuracy and increasing speed fivefold. Kraken 2 also introduces a translated search mode, providing increased sensitivity in viral metagenomics analysis.},
	language = {en},
	number = {1},
	urldate = {2023-10-27},
	journal = {Genome Biology},
	author = {Wood, Derrick E. and Lu, Jennifer and Langmead, Ben},
	month = nov,
	year = {2019},
	pages = {257},
}

@misc{harshil_patel_nf-corernaseq_2023,
	title = {nf-core/rnaseq: nf-core/rnaseq v3.12.0 - {Osmium} {Octopus}},
	copyright = {Open Access},
	shorttitle = {nf-core/rnaseq},
	url = {https://zenodo.org/record/7998767},
	abstract = {[3.12.0] - 2023-06-02 Credits Special thanks to the following for their contributions to the release: Adam Talbot Esha Joshi Ghepardo Matthias Zepper Maxime Garcia Rob Syme Thank you to everyone else that has contributed by reporting bugs, enhancements or in any other way, shape or form. Enhancements \&amp; fixes [\#1011] - FastQ files from UMI-tools not being passed to fastp [\#1018] - Ability to skip both alignment and pseudo-alignment to only run pre-processing QC steps. PR \#1016 - Updated pipeline template to nf-core/tools 2.8 PR \#1025 - Add {\textless}code{\textgreater}public\_aws\_ecr.config{\textless}/code{\textgreater} to source mulled containers when using {\textless}code{\textgreater}public.ecr.aws{\textless}/code{\textgreater} Docker Biocontainer registry PR \#1038 - Updated error log for count values when supplying {\textless}code{\textgreater}--additional\_fasta{\textless}/code{\textgreater} PR \#1042 - revert samtools\_sort modules to no memory assignement Parameters Old parameter New parameter {\textless}code{\textgreater}--skip\_pseudo\_alignment{\textless}/code{\textgreater} {\textless}strong{\textgreater}NB:{\textless}/strong{\textgreater} Parameter has been {\textless}strong{\textgreater}updated{\textless}/strong{\textgreater} if both old and new parameter information is present. {\textless}strong{\textgreater}NB:{\textless}/strong{\textgreater} Parameter has been {\textless}strong{\textgreater}added{\textless}/strong{\textgreater} if just the new parameter information is present. {\textless}strong{\textgreater}NB:{\textless}/strong{\textgreater} Parameter has been {\textless}strong{\textgreater}removed{\textless}/strong{\textgreater} if new parameter information isn't present. Software dependencies Dependency Old version New version {\textless}code{\textgreater}fastp{\textless}/code{\textgreater} 0.23.2 0.23.4 {\textless}code{\textgreater}samtools{\textless}/code{\textgreater} 1.16.1 1.17 {\textless}strong{\textgreater}NB:{\textless}/strong{\textgreater} Dependency has been {\textless}strong{\textgreater}updated{\textless}/strong{\textgreater} if both old and new version information is present. {\textless}strong{\textgreater}NB:{\textless}/strong{\textgreater} Dependency has been {\textless}strong{\textgreater}added{\textless}/strong{\textgreater} if just the new version information is present. {\textless}strong{\textgreater}NB:{\textless}/strong{\textgreater} Dependency has been {\textless}strong{\textgreater}removed{\textless}/strong{\textgreater} if new version information isn't present.},
	urldate = {2023-10-27},
	publisher = {Zenodo},
	author = {{Harshil Patel} and Ewels, Phil and Peltzer, Alexander and Botvinnik, Olga and Sturm, Gregor and Moreno, Denis and {Pranathi Vemuri} and Garcia, Maxime U and {Silviamorins} and Pantano, Lorena and Binzer-Panchal, Mahesh and {Nf-Core Bot} and Syme, Robert and Zepper, Matthias and Kelly, Gavin and Hanssen, Friederike and Yates, James A. Fellows and Cheshire, Chris and {Rfenouil} and Espinosa-Carrasco, Jose and {Marchoeppner} and Miller, Edmund and Talbot, Adam and Zhou, Peng and Guinchard, Sarah and Hörtenhuber, Matthias and Gabernet, Gisela and Mertes, Christian and Straub, Daniel and Di Tommaso, Paolo},
	month = jun,
	year = {2023},
	doi = {10.5281/ZENODO.7998767},
}

@article{price_pacbio_2022,
	title = {{PacBio} {HiFi} genome assembly using hifiasm v2.1},
	url = {https://workflowhub.eu/workflows/221?version=3},
	doi = {10.48546/WORKFLOWHUB.WORKFLOW.221.3},
	abstract = {\# PacBio HiFi genome assembly using hifiasm v2.1 \#\# General usage recommendations Please see the [Genome assembly with hifiasm on Galaxy Australia](https://australianbiocommons.github.io/how-to-guides/genome\_assembly/hifi\_assembly) guide. \#\# See [change log](./change\_log.md) \#\# Acknowledgements The workflow \&amp; the [doc\_guidelines template used](https://github.com/AustralianBioCommons/doc\_guidelines) are supported by the Australian BioCommons via Bioplatforms Australia funding, the Australian Research Data Commons (https://doi.org/10.47486/PL105) and the Queensland Government RICF programme. Bioplatforms Australia and the Australian Research Data Commons are enabled by the National Collaborative Research Infrastructure Strategy (NCRIS).},
	urldate = {2023-10-27},
	author = {Price, Gareth and Farquharson, Katherine},
	year = {2022},
}

@misc{oelsner_readmeso_nodate,
	title = {readme.so},
	url = {https://readme.so/},
	abstract = {Use readme.so's markdown editor and templates to easily create a ReadMe for your projects},
	language = {en},
	urldate = {2023-10-27},
	journal = {readme.so},
	author = {Oelsner, Katherine},
}

@article{hermann_documenting_2022,
	title = {Documenting research software in engineering science},
	volume = {12},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-10376-9},
	doi = {10.1038/s41598-022-10376-9},
	abstract = {Abstract 
            The reuse of research software needs good documentation, however, the documentation in particular is often criticized. Especially in non-IT specific disciplines, the lack of documentation is attributed to the lack of training, the lack of time or missing rewards. This article addresses the hypothesis that scientists do document but do not know exactly what they need to document, why, and for whom. In order to evaluate the actual documentation practice of research software, we examined existing recommendations, and we evaluated their implementation in everyday practice using a concrete example from the engineering sciences and compared the findings with best practice examples. To get a broad overview of what documentation of research software entailed, we defined categories and used them to conduct the research. Our results show that the big picture of what documentation of research software means is missing. Recommendations do not consider the important role of researchers, who write research software, whose documentation takes mainly place in their research articles. Moreover, we show that research software always has a history that influences the documentation.},
	language = {en},
	number = {1},
	urldate = {2023-10-27},
	journal = {Scientific Reports},
	author = {Hermann, Sibylle and Fehr, Jörg},
	month = apr,
	year = {2022},
	pages = {6567},
}

@misc{jones_codemeta_2017,
	title = {{CodeMeta}: an exchange schema for software metadata},
	shorttitle = {{CodeMeta}},
	url = {https://raw.githubusercontent.com/codemeta/codemeta/2.0/codemeta.jsonld},
	urldate = {2023-10-27},
	publisher = {KNB Data Repository},
	author = {Jones, Matthew B and Boettiger, Carl and Mayes, Abby Cabunoc and {Arfon Smith} and Slaughter, Peter and Niemeyer, Kyle and Gil, Yolanda and Fenner, Martin and Nowak, Krzysztof and Hahnel, Mark and Coy, Luke and Allen, Alice and Crosas, Mercè and Sands, Ashley and Hong, Neil Chue and Cruse, Patricia and Katz, Dan and Goble, Carole},
	year = {2017},
	doi = {10.5063/SCHEMA/CODEMETA-2.0},
}

@article{sansone_fairsharing_2019,
	title = {{FAIRsharing} as a community approach to standards, repositories and policies},
	volume = {37},
	issn = {1087-0156, 1546-1696},
	url = {https://www.nature.com/articles/s41587-019-0080-8},
	doi = {10.1038/s41587-019-0080-8},
	language = {en},
	number = {4},
	urldate = {2023-10-27},
	journal = {Nature Biotechnology},
	author = {Sansone, Susanna-Assunta and McQuilton, Peter and Rocca-Serra, Philippe and Gonzalez-Beltran, Alejandra and Izzo, Massimiliano and Lister, Allyson L. and Thurston, Milo and {the FAIRsharing Community}},
	month = apr,
	year = {2019},
	pages = {358--367},
}

@misc{noauthor_mit_nodate,
	title = {{MIT} {License} {\textbar} {Software} {Package} {Data} {Exchange} ({SPDX})},
	url = {https://spdx.org/licenses/MIT.html},
	urldate = {2023-10-27},
}

@article{lee_ten_2018,
	title = {Ten simple rules for documenting scientific software},
	volume = {14},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1006561},
	doi = {10.1371/journal.pcbi.1006561},
	language = {en},
	number = {12},
	urldate = {2023-10-26},
	journal = {PLOS Computational Biology},
	author = {Lee, Benjamin D.},
	editor = {Markel, Scott},
	month = dec,
	year = {2018},
	pages = {e1006561},
}

@article{goble_implementing_2021,
	title = {Implementing {FAIR} {Digital} {Objects} in the {EOSC}-{Life} {Workflow} {Collaboratory}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/4605654},
	doi = {10.5281/ZENODO.4605654},
	abstract = {The practice of performing computational processes using workflows has taken hold in the biosciences as the discipline becomes increasingly computational. The COVID-19 pandemic has spotlighted the importance of systematic and shared analysis of SARS-CoV-2 and its data processing pipelines. This is coupled with a drive in the community towards adopting FAIR practices (Findable, Accessible, Interoperable, and Reusable) not just for data, but also for workflows, and to improve the reproducibility of processes, both manual and computational. EOSC-Life brings together 13 of the Life Science ‘ESFRI’ research infrastructures to create an open, digital and collaborative space for biological and medical research. The project is developing a cloud-based {\textless}strong{\textgreater}workflow collaboratory {\textless}/strong{\textgreater}to drive implementation of FAIR workflows across disciplines and RI boundaries, and foster tool- focused collaborations and reuse between communities via the sharing of data analysis workflows. The collaboratory aims to provide a framework for researchers and workflow specialists to use and reuse workflows. As such it is an example of the {\textless}em{\textgreater}Canonical Workflow Frameworks for Research{\textless}/em{\textgreater} ({\textless}strong{\textgreater}CWFR{\textless}/strong{\textgreater}) vision in practice. EOSC-Life is made up of established research infrastructures ranging from biobanking and clinical trial management, through to coordinating biomedical imaging and plant phenotyping to multi-omic and systems-based data analysis. The heterogeneity of the disciplines is reflected in the diversity of their data analysis needs and practices and the variety of workflow management systems they use. Many have specialist platforms developed over years. Workflow management systems in common use include Galaxy, Snakemake, and Nextflow, and more specialist, domain-specific systems such as SCIPION. To serve the needs of this established and diverse community, EOSC-Life has developed {\textless}strong{\textgreater}WorkflowHub{\textless}/strong{\textgreater} as an inclusive workflow registry, agnostic to any {\textless}em{\textgreater}Workflow Management System {\textless}/em{\textgreater}({\textless}strong{\textgreater}WfMS{\textless}/strong{\textgreater}). WorkflowHub aims to incorporate their workflows in partnership with the WfMS, to embed the registration of workflows in the community processes, e.g. based on pre-existing workflow repositories. The registry adopts common practices, e.g.use of GitHub repositories, and supports integration with the ecosystem of tool packages, assisted by registries (bio.tools, biocontainers), and services for testing and benchmarking workflows (OpenEBench, LifeMonitor). As an umbrella registry, the Hub makes workflows Findable and Accessible by indexing workflows across workflow management systems and their native repositories, while providing rich standardized metadata. Interoperability and Reusability is supported by standardized descriptions of workflows and packaging of workflow components, developed in close collaboration with the communities. The WorkflowHub creates a place for registering and discovering libraries of workflows developed by collaborating teams, with suitable features for versioning, credit, analytics, and import/export needed to support the reuse of workflows, the development of sub-workflows as canonical steps and ultimately the identification of common patterns in the workflows. At the heart of the collaboratory is a Digital Object framework for documenting and exchanging workflows annotated with machine processable metadata produced and consumed by the participating platforms. The Digital Object framework is founded on several needs: {\textless}em{\textgreater}Describing a workflow and its steps in a canonical, normalised and WfMS independent way{\textless}/em{\textgreater}: we use the {\textless}strong{\textgreater}Common Workflow Language (CWL){\textless}/strong{\textgreater}, more specifically the {\textless}em{\textgreater}Abstract CWL {\textless}/em{\textgreater}(non-executable) description variant to accompany the native workflow definitions. This presents the structure, composed tools and external interface in an interoperable way across workflow languages. WfMS can generate abstract CWL, already demonstrated for Galaxy, next to the ‘native’ Galaxy workflow description. This language duality is an important retention aspect of {\textless}em{\textgreater}reproducibility{\textless}/em{\textgreater}, as the structure and metadata of the workflow can be accessed independent of its native format as CWL, even if that may no longer be executable, capturing the {\textless}em{\textgreater}canonical workflow {\textless}/em{\textgreater}in a FAIR format. The co-presence of the native format enables direct reuse in the specific WfMS, benefitting from all its features. {\textless}em{\textgreater}Metadata about a workflow and its tools using a minimal information model: {\textless}/em{\textgreater}we use the {\textless}strong{\textgreater}Bioschemas {\textless}/strong{\textgreater}profiles Computational Tool, Computational Workflow and Formal Parameter which are discipline independent, opinionated conventions for using schema.org annotations. Bioschemas enables us to capture and publish workflow registrations and their metadata as FAIR Digital Objects. The EDAM Ontology is further used to add bioinformatics-specific metadata, such as strong typing of inputs and outputs, within both Abstract CWL and Bioschemas annotations. {\textless}em{\textgreater}Organising and packaging the definitions and components of a workflow {\textless}/em{\textgreater}with their associated objects such as test data: we use a Workflow profile specialisation of {\textless}strong{\textgreater}RO-Crate{\textless}/strong{\textgreater}, a community developed standardised approach for research output packaging with rich metadata. RO-Crate provides us the ability to package executable workflows, their components such as example and test data, abstract CWL, diagrams and their documentation. This makes workflows more readily re-usable. RO-Crate is the base unit of upload and download at the WorkflowHub. As CWFR Digital Objects of workflows, RO-Crates are activation-ready and circulated between the different services for execution and testing. {\textless}em{\textgreater}Identifiers {\textless}/em{\textgreater}for all the components: like FAIR Digital Objects, RO-Crates can be metadata-rich bags of identifiers and can themselves be assigned permanent identifiers. This enables the full description of a computational analysis, from input data, over tools and workflows, to final results. Using these components we have built an environment that supports the Workflow Life Cycle, from abstract description, through to a specific rendering in a WfMS to its execution and the documentation of its run provenance, results and continued testing.},
	urldate = {2023-10-26},
	author = {Goble, Carole and Soiland-Reyes, Stian and Bacall, Finn and Owen, Stuart and Williams, Alan and Eguinoa, Ignacio and Droesbeke, Bert and Leo, Simone and Pireddu, Luca and Rodríguez-Navas, Laura and Fernández, José Mª and Capella-Gutierrez, Salvador and Ménager, Hervé and Grüning, Björn and Serrano-Solano, Beatriz and Ewels, Philip and Coppens, Frederik},
	month = mar,
	year = {2021},
}

@misc{fouilloux_galaxy_2021,
	title = {Galaxy workflow from {Galaxy} 101 for everyone},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/5090049},
	doi = {10.5281/ZENODO.5090049},
	abstract = {Galaxy workflow from Galaxy 101 for everyone. This workflow is used in the training "How to reproduce published Galaxy analyses" to learn how to run a published Galaxy workflow.},
	language = {en},
	urldate = {2023-10-26},
	publisher = {Zenodo},
	author = {Fouilloux, Anne and Föll, Melanie},
	month = jul,
	year = {2021},
	keywords = {galaxy, workflow},
}

@misc{noauthor_open_2021,
	title = {Open {Source} {Software} {Licenses} 101: {The} {MIT} {License} - {FOSSA}},
	shorttitle = {Open {Source} {Software} {Licenses} 101},
	url = {https://fossa.com/blog/open-source-licenses-101-mit-license/},
	abstract = {Get an overview of the extremely popular MIT open source software license, including what it allows, prohibits, and requires of its users.},
	language = {en},
	urldate = {2023-10-26},
	journal = {Dependency Heaven},
	month = jan,
	year = {2021},
}

@article{druskat_citation_2021,
	title = {Citation {File} {Format}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/5171937},
	doi = {10.5281/ZENODO.5171937},
	abstract = {CITATION.cff files are plain text files with human- and machine-readable citation information for software. Code developers can include them in their repositories to let others know how to correctly cite their software. This is the specification for the Citation File Format.},
	language = {en},
	urldate = {2023-10-26},
	author = {Druskat, Stephan and Spaaks, Jurriaan H. and Chue Hong, Neil and Haines, Robert and Baker, James and Bliven, Spencer and Willighagen, Egon and Pérez-Suárez, David and Konovalov, Alexander},
	month = aug,
	year = {2021},
	keywords = {CFF, YAML, citation file format, citation files, credit, file format, research software, software citation, software sustainability},
}

@article{ison_biotools_2019,
	title = {The bio.tools registry of software tools and data resources for the life sciences},
	volume = {20},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1772-6},
	doi = {10.1186/s13059-019-1772-6},
	language = {en},
	number = {1},
	urldate = {2023-10-26},
	journal = {Genome Biology},
	author = {Ison, Jon and Ienasescu, Hans and Chmura, Piotr and Rydza, Emil and Ménager, Hervé and Kalaš, Matúš and Schwämmle, Veit and Grüning, Björn and Beard, Niall and Lopez, Rodrigo and Duvaud, Severine and Stockinger, Heinz and Persson, Bengt and Vařeková, Radka Svobodová and Raček, Tomáš and Vondrášek, Jiří and Peterson, Hedi and Salumets, Ahto and Jonassen, Inge and Hooft, Rob and Nyrönen, Tommi and Valencia, Alfonso and Capella, Salvador and Gelpí, Josep and Zambelli, Federico and Savakis, Babis and Leskošek, Brane and Rapacki, Kristoffer and Blanchet, Christophe and Jimenez, Rafael and Oliveira, Arlindo and Vriend, Gert and Collin, Olivier and Van Helden, Jacques and Løngreen, Peter and Brunak, Søren},
	month = dec,
	year = {2019},
	pages = {164},
}

@article{ison_edam_2013,
	title = {{EDAM}: an ontology of bioinformatics operations, types of data and identifiers, topics and formats},
	volume = {29},
	issn = {1367-4811, 1367-4803},
	shorttitle = {{EDAM}},
	url = {https://academic.oup.com/bioinformatics/article/29/10/1325/255660},
	doi = {10.1093/bioinformatics/btt113},
	abstract = {Abstract 
            Motivation: Advancing the search, publication and integration of bioinformatics tools and resources demands consistent machine-understandable descriptions. A comprehensive ontology allowing such descriptions is therefore required. 
            Results: EDAM is an ontology of bioinformatics operations (tool or workflow functions), types of data and identifiers, application domains and data formats. EDAM supports semantic annotation of diverse entities such as Web services, databases, programmatic libraries, standalone tools, interactive applications, data schemas, datasets and publications within bioinformatics. EDAM applies to organizing and finding suitable tools and data and to automating their integration into complex applications or workflows. It includes over 2200 defined concepts and has successfully been used for annotations and implementations. 
            Availability: The latest stable version of EDAM is available in OWL format from http://edamontology.org/EDAM.owl and in OBO format from http://edamontology.org/EDAM.obo. It can be viewed online at the NCBO BioPortal and the EBI Ontology Lookup Service. For documentation and license please refer to http://edamontology.org. This article describes version 1.2 available at http://edamontology.org/EDAM\_1.2.owl. 
            Contact:  jison@ebi.ac.uk},
	language = {en},
	number = {10},
	urldate = {2023-10-26},
	journal = {Bioinformatics},
	author = {Ison, Jon and Kalaš, Matúš and Jonassen, Inge and Bolser, Dan and Uludag, Mahmut and McWilliam, Hamish and Malone, James and Lopez, Rodrigo and Pettifer, Steve and Rice, Peter},
	month = may,
	year = {2013},
	pages = {1325--1332},
}

@article{cormier_samba_2021,
	title = {{SAMBA}: {Standardized} and {Automated} {MetaBarcoding} {Analyses} workflow},
	shorttitle = {{SAMBA}},
	url = {https://workflowhub.eu/workflows/156?version=1},
	doi = {10.48546/WORKFLOWHUB.WORKFLOW.156.1},
	abstract = {SAMBA is a FAIR scalable workflow integrating, into a unique tool, state-of-the-art bioinformatics and statistical methods to conduct reproducible eDNA analyses using Nextflow. SAMBA starts processing by verifying integrity of raw reads and metadata. Then all bioinformatics processing is done using commonly used procedure (QIIME 2 and DADA2) but adds new steps relying on dbOTU3 and microDecon to build high quality ASV count tables. Extended statistical analyses are also performed. Finally, SAMBA produces a full dynamic HTML report including resources used, commands executed, intermediate results, statistical analyses and figures. The SAMBA pipeline can run tasks across multiple compute infrastructures in a very portable manner. It comes with singularity containers making installation trivial and results highly reproducible.},
	urldate = {2023-10-26},
	author = {Cormier, Alexandre and Durand, Patrick and Noel, Cyril and Leroi, Laura},
	year = {2021},
}

@article{maier_sars-cov-2-pe-illumina-artic-variant-callingcovid-19-pe-artic-illumina_2022,
	title = {sars-cov-2-pe-illumina-artic-variant-calling/{COVID}-19-{PE}-{ARTIC}-{ILLUMINA}},
	url = {https://workflowhub.eu/workflows/110?version=7},
	doi = {10.48546/WORKFLOWHUB.WORKFLOW.110.7},
	abstract = {COVID-19: variation analysis on ARTIC PE data --------------------------------------------- The workflow for Illumina-sequenced ampliconic data builds on the RNASeq workflow for paired-end data using the same steps for mapping and variant calling, but adds extra logic for trimming amplicon primer sequences off reads with the ivar package. In addition, this workflow uses ivar also to identify amplicons affected by primer-binding site mutations and, if possible, excludes reads derived from such "tainted" amplicons when calculating allele-frequencies of other variants.},
	urldate = {2023-10-26},
	author = {Maier, Wolfgang},
	year = {2022},
}
