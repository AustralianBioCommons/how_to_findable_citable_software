
@article{lee_ten_2018,
	title = {Ten simple rules for documenting scientific software},
	volume = {14},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1006561},
	doi = {10.1371/journal.pcbi.1006561},
	language = {en},
	number = {12},
	urldate = {2023-10-26},
	journal = {PLOS Computational Biology},
	author = {Lee, Benjamin D.},
	editor = {Markel, Scott},
	month = dec,
	year = {2018},
	pages = {e1006561},
}

@article{goble_implementing_2021,
	title = {Implementing {FAIR} {Digital} {Objects} in the {EOSC}-{Life} {Workflow} {Collaboratory}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/4605654},
	doi = {10.5281/ZENODO.4605654},
	abstract = {The practice of performing computational processes using workflows has taken hold in the biosciences as the discipline becomes increasingly computational. The COVID-19 pandemic has spotlighted the importance of systematic and shared analysis of SARS-CoV-2 and its data processing pipelines. This is coupled with a drive in the community towards adopting FAIR practices (Findable, Accessible, Interoperable, and Reusable) not just for data, but also for workflows, and to improve the reproducibility of processes, both manual and computational. EOSC-Life brings together 13 of the Life Science ‘ESFRI’ research infrastructures to create an open, digital and collaborative space for biological and medical research. The project is developing a cloud-based {\textless}strong{\textgreater}workflow collaboratory {\textless}/strong{\textgreater}to drive implementation of FAIR workflows across disciplines and RI boundaries, and foster tool- focused collaborations and reuse between communities via the sharing of data analysis workflows. The collaboratory aims to provide a framework for researchers and workflow specialists to use and reuse workflows. As such it is an example of the {\textless}em{\textgreater}Canonical Workflow Frameworks for Research{\textless}/em{\textgreater} ({\textless}strong{\textgreater}CWFR{\textless}/strong{\textgreater}) vision in practice. EOSC-Life is made up of established research infrastructures ranging from biobanking and clinical trial management, through to coordinating biomedical imaging and plant phenotyping to multi-omic and systems-based data analysis. The heterogeneity of the disciplines is reflected in the diversity of their data analysis needs and practices and the variety of workflow management systems they use. Many have specialist platforms developed over years. Workflow management systems in common use include Galaxy, Snakemake, and Nextflow, and more specialist, domain-specific systems such as SCIPION. To serve the needs of this established and diverse community, EOSC-Life has developed {\textless}strong{\textgreater}WorkflowHub{\textless}/strong{\textgreater} as an inclusive workflow registry, agnostic to any {\textless}em{\textgreater}Workflow Management System {\textless}/em{\textgreater}({\textless}strong{\textgreater}WfMS{\textless}/strong{\textgreater}). WorkflowHub aims to incorporate their workflows in partnership with the WfMS, to embed the registration of workflows in the community processes, e.g. based on pre-existing workflow repositories. The registry adopts common practices, e.g.use of GitHub repositories, and supports integration with the ecosystem of tool packages, assisted by registries (bio.tools, biocontainers), and services for testing and benchmarking workflows (OpenEBench, LifeMonitor). As an umbrella registry, the Hub makes workflows Findable and Accessible by indexing workflows across workflow management systems and their native repositories, while providing rich standardized metadata. Interoperability and Reusability is supported by standardized descriptions of workflows and packaging of workflow components, developed in close collaboration with the communities. The WorkflowHub creates a place for registering and discovering libraries of workflows developed by collaborating teams, with suitable features for versioning, credit, analytics, and import/export needed to support the reuse of workflows, the development of sub-workflows as canonical steps and ultimately the identification of common patterns in the workflows. At the heart of the collaboratory is a Digital Object framework for documenting and exchanging workflows annotated with machine processable metadata produced and consumed by the participating platforms. The Digital Object framework is founded on several needs: {\textless}em{\textgreater}Describing a workflow and its steps in a canonical, normalised and WfMS independent way{\textless}/em{\textgreater}: we use the {\textless}strong{\textgreater}Common Workflow Language (CWL){\textless}/strong{\textgreater}, more specifically the {\textless}em{\textgreater}Abstract CWL {\textless}/em{\textgreater}(non-executable) description variant to accompany the native workflow definitions. This presents the structure, composed tools and external interface in an interoperable way across workflow languages. WfMS can generate abstract CWL, already demonstrated for Galaxy, next to the ‘native’ Galaxy workflow description. This language duality is an important retention aspect of {\textless}em{\textgreater}reproducibility{\textless}/em{\textgreater}, as the structure and metadata of the workflow can be accessed independent of its native format as CWL, even if that may no longer be executable, capturing the {\textless}em{\textgreater}canonical workflow {\textless}/em{\textgreater}in a FAIR format. The co-presence of the native format enables direct reuse in the specific WfMS, benefitting from all its features. {\textless}em{\textgreater}Metadata about a workflow and its tools using a minimal information model: {\textless}/em{\textgreater}we use the {\textless}strong{\textgreater}Bioschemas {\textless}/strong{\textgreater}profiles Computational Tool, Computational Workflow and Formal Parameter which are discipline independent, opinionated conventions for using schema.org annotations. Bioschemas enables us to capture and publish workflow registrations and their metadata as FAIR Digital Objects. The EDAM Ontology is further used to add bioinformatics-specific metadata, such as strong typing of inputs and outputs, within both Abstract CWL and Bioschemas annotations. {\textless}em{\textgreater}Organising and packaging the definitions and components of a workflow {\textless}/em{\textgreater}with their associated objects such as test data: we use a Workflow profile specialisation of {\textless}strong{\textgreater}RO-Crate{\textless}/strong{\textgreater}, a community developed standardised approach for research output packaging with rich metadata. RO-Crate provides us the ability to package executable workflows, their components such as example and test data, abstract CWL, diagrams and their documentation. This makes workflows more readily re-usable. RO-Crate is the base unit of upload and download at the WorkflowHub. As CWFR Digital Objects of workflows, RO-Crates are activation-ready and circulated between the different services for execution and testing. {\textless}em{\textgreater}Identifiers {\textless}/em{\textgreater}for all the components: like FAIR Digital Objects, RO-Crates can be metadata-rich bags of identifiers and can themselves be assigned permanent identifiers. This enables the full description of a computational analysis, from input data, over tools and workflows, to final results. Using these components we have built an environment that supports the Workflow Life Cycle, from abstract description, through to a specific rendering in a WfMS to its execution and the documentation of its run provenance, results and continued testing.},
	urldate = {2023-10-26},
	author = {Goble, Carole and Soiland-Reyes, Stian and Bacall, Finn and Owen, Stuart and Williams, Alan and Eguinoa, Ignacio and Droesbeke, Bert and Leo, Simone and Pireddu, Luca and Rodríguez-Navas, Laura and Fernández, José Mª and Capella-Gutierrez, Salvador and Ménager, Hervé and Grüning, Björn and Serrano-Solano, Beatriz and Ewels, Philip and Coppens, Frederik},
	month = mar,
	year = {2021},
}

@misc{fouilloux_galaxy_2021,
	title = {Galaxy workflow from {Galaxy} 101 for everyone},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/5090049},
	doi = {10.5281/ZENODO.5090049},
	abstract = {Galaxy workflow from Galaxy 101 for everyone. This workflow is used in the training "How to reproduce published Galaxy analyses" to learn how to run a published Galaxy workflow.},
	language = {en},
	urldate = {2023-10-26},
	publisher = {Zenodo},
	author = {Fouilloux, Anne and Föll, Melanie},
	month = jul,
	year = {2021},
	keywords = {galaxy, workflow},
}

@misc{noauthor_open_2021,
	title = {Open {Source} {Software} {Licenses} 101: {The} {MIT} {License} - {FOSSA}},
	shorttitle = {Open {Source} {Software} {Licenses} 101},
	url = {https://fossa.com/blog/open-source-licenses-101-mit-license/},
	abstract = {Get an overview of the extremely popular MIT open source software license, including what it allows, prohibits, and requires of its users.},
	language = {en},
	urldate = {2023-10-26},
	journal = {Dependency Heaven},
	month = jan,
	year = {2021},
}

@article{druskat_citation_2021,
	title = {Citation {File} {Format}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/5171937},
	doi = {10.5281/ZENODO.5171937},
	abstract = {CITATION.cff files are plain text files with human- and machine-readable citation information for software. Code developers can include them in their repositories to let others know how to correctly cite their software. This is the specification for the Citation File Format.},
	language = {en},
	urldate = {2023-10-26},
	author = {Druskat, Stephan and Spaaks, Jurriaan H. and Chue Hong, Neil and Haines, Robert and Baker, James and Bliven, Spencer and Willighagen, Egon and Pérez-Suárez, David and Konovalov, Alexander},
	month = aug,
	year = {2021},
	keywords = {CFF, YAML, citation file format, citation files, credit, file format, research software, software citation, software sustainability},
}

@article{ison_biotools_2019,
	title = {The bio.tools registry of software tools and data resources for the life sciences},
	volume = {20},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1772-6},
	doi = {10.1186/s13059-019-1772-6},
	language = {en},
	number = {1},
	urldate = {2023-10-26},
	journal = {Genome Biology},
	author = {Ison, Jon and Ienasescu, Hans and Chmura, Piotr and Rydza, Emil and Ménager, Hervé and Kalaš, Matúš and Schwämmle, Veit and Grüning, Björn and Beard, Niall and Lopez, Rodrigo and Duvaud, Severine and Stockinger, Heinz and Persson, Bengt and Vařeková, Radka Svobodová and Raček, Tomáš and Vondrášek, Jiří and Peterson, Hedi and Salumets, Ahto and Jonassen, Inge and Hooft, Rob and Nyrönen, Tommi and Valencia, Alfonso and Capella, Salvador and Gelpí, Josep and Zambelli, Federico and Savakis, Babis and Leskošek, Brane and Rapacki, Kristoffer and Blanchet, Christophe and Jimenez, Rafael and Oliveira, Arlindo and Vriend, Gert and Collin, Olivier and Van Helden, Jacques and Løngreen, Peter and Brunak, Søren},
	month = dec,
	year = {2019},
	pages = {164},
}

@article{ison_edam_2013,
	title = {{EDAM}: an ontology of bioinformatics operations, types of data and identifiers, topics and formats},
	volume = {29},
	issn = {1367-4811, 1367-4803},
	shorttitle = {{EDAM}},
	url = {https://academic.oup.com/bioinformatics/article/29/10/1325/255660},
	doi = {10.1093/bioinformatics/btt113},
	abstract = {Abstract 
            Motivation: Advancing the search, publication and integration of bioinformatics tools and resources demands consistent machine-understandable descriptions. A comprehensive ontology allowing such descriptions is therefore required. 
            Results: EDAM is an ontology of bioinformatics operations (tool or workflow functions), types of data and identifiers, application domains and data formats. EDAM supports semantic annotation of diverse entities such as Web services, databases, programmatic libraries, standalone tools, interactive applications, data schemas, datasets and publications within bioinformatics. EDAM applies to organizing and finding suitable tools and data and to automating their integration into complex applications or workflows. It includes over 2200 defined concepts and has successfully been used for annotations and implementations. 
            Availability: The latest stable version of EDAM is available in OWL format from http://edamontology.org/EDAM.owl and in OBO format from http://edamontology.org/EDAM.obo. It can be viewed online at the NCBO BioPortal and the EBI Ontology Lookup Service. For documentation and license please refer to http://edamontology.org. This article describes version 1.2 available at http://edamontology.org/EDAM\_1.2.owl. 
            Contact:  jison@ebi.ac.uk},
	language = {en},
	number = {10},
	urldate = {2023-10-26},
	journal = {Bioinformatics},
	author = {Ison, Jon and Kalaš, Matúš and Jonassen, Inge and Bolser, Dan and Uludag, Mahmut and McWilliam, Hamish and Malone, James and Lopez, Rodrigo and Pettifer, Steve and Rice, Peter},
	month = may,
	year = {2013},
	pages = {1325--1332},
}

@article{cormier_samba_2021,
	title = {{SAMBA}: {Standardized} and {Automated} {MetaBarcoding} {Analyses} workflow},
	shorttitle = {{SAMBA}},
	url = {https://workflowhub.eu/workflows/156?version=1},
	doi = {10.48546/WORKFLOWHUB.WORKFLOW.156.1},
	abstract = {SAMBA is a FAIR scalable workflow integrating, into a unique tool, state-of-the-art bioinformatics and statistical methods to conduct reproducible eDNA analyses using Nextflow. SAMBA starts processing by verifying integrity of raw reads and metadata. Then all bioinformatics processing is done using commonly used procedure (QIIME 2 and DADA2) but adds new steps relying on dbOTU3 and microDecon to build high quality ASV count tables. Extended statistical analyses are also performed. Finally, SAMBA produces a full dynamic HTML report including resources used, commands executed, intermediate results, statistical analyses and figures. The SAMBA pipeline can run tasks across multiple compute infrastructures in a very portable manner. It comes with singularity containers making installation trivial and results highly reproducible.},
	urldate = {2023-10-26},
	author = {Cormier, Alexandre and Durand, Patrick and Noel, Cyril and Leroi, Laura},
	year = {2021},
}

@article{maier_sars-cov-2-pe-illumina-artic-variant-callingcovid-19-pe-artic-illumina_2022,
	title = {sars-cov-2-pe-illumina-artic-variant-calling/{COVID}-19-{PE}-{ARTIC}-{ILLUMINA}},
	url = {https://workflowhub.eu/workflows/110?version=7},
	doi = {10.48546/WORKFLOWHUB.WORKFLOW.110.7},
	abstract = {COVID-19: variation analysis on ARTIC PE data --------------------------------------------- The workflow for Illumina-sequenced ampliconic data builds on the RNASeq workflow for paired-end data using the same steps for mapping and variant calling, but adds extra logic for trimming amplicon primer sequences off reads with the ivar package. In addition, this workflow uses ivar also to identify amplicons affected by primer-binding site mutations and, if possible, excludes reads derived from such "tainted" amplicons when calculating allele-frequencies of other variants.},
	urldate = {2023-10-26},
	author = {Maier, Wolfgang},
	year = {2022},
}
